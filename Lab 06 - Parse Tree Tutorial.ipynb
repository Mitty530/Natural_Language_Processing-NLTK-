{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse Tree 01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'write', 'a', 'book']\n",
      "(S (NP I) (VP (V write) (NP (Det a) (N book))))\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "text2 = nltk.CFG.fromstring(\"\"\"\n",
    "S -> NP VP \n",
    "PP -> P NP \n",
    "NP -> Det N | PP NP | Det N PP | 'I'\n",
    "VP -> V NP | VP PP | V \n",
    "Det -> 'a'\n",
    "N -> 'book'\n",
    "V -> 'write'\n",
    "\"\"\")\n",
    "text1 = nltk.tokenize.word_tokenize(\"I write a book\")\n",
    "print(text1)\n",
    "parser = nltk.ChartParser(text2)\n",
    "for tree in parser.parse(text1):\n",
    "    tree.draw()\n",
    "print(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse Tree 02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP I)\n",
      "  (VP\n",
      "    (V shot)\n",
      "    (NP (Det an) (N elephant) (PP (P in) (NP (Det my) (N pajamas))))))\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "groucho_grammar = nltk.CFG.fromstring(\"\"\"\n",
    "S -> NP VP \n",
    "PP -> P NP \n",
    "NP -> Det N | Det N PP | 'I' \n",
    "VP -> V NP | VP PP \n",
    "Det -> 'an' | 'my' \n",
    "N -> 'elephant' | 'pajamas' \n",
    "V -> 'shot' \n",
    "P -> 'in' \n",
    "\"\"\")\n",
    "\n",
    "sent = ['I', 'shot', 'an', 'elephant', 'in', 'my', 'pajamas']\n",
    "parser = nltk.ChartParser(groucho_grammar)\n",
    "for tree in parser.parse(sent):\n",
    "    tree.draw()\n",
    "print(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse Tree 03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Alice', 'loves', 'Bob']\n",
      "\n",
      "(S\n",
      "  (NP (Det ) (N Alice))\n",
      "  (VP (VP (V loves)) (PP (P ) (NP (Det ) (N Bob)))))\n",
      "['Alice', 'loves', 'Bob']\n",
      "\n",
      "(S (NP (N Alice)) (VP (V loves) (NP (N Bob))))\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "text2 = nltk.CFG.fromstring(\"\"\"\n",
    "S -> NP VP \n",
    "PP -> P NP \n",
    "NP -> Det N | PP NP | Det N PP\n",
    "VP -> V NP | VP PP | V \n",
    "N -> 'Alice' | 'Bob'\n",
    "V -> 'loves'\n",
    "Det -> \n",
    "P -> \n",
    "\"\"\")\n",
    "text1 = nltk.tokenize.word_tokenize(\"Alice loves Bob\")\n",
    "print(text1)\n",
    "print()\n",
    "parser = nltk.ChartParser(text2)\n",
    "for tree in parser.parse(text1):\n",
    "    tree.draw()\n",
    "print(tree)\n",
    "\n",
    "# ~~~~~~~~~~~~~~~~~~~~ Another way of writing the code ~~~~~~~~~~~~~~~~~~~~ \n",
    "\n",
    "import nltk\n",
    "\n",
    "text2 = nltk.CFG.fromstring(\"\"\"\n",
    "S -> NP VP \n",
    "NP -> N\n",
    "VP -> V NP | VP PP | V \n",
    "N -> 'Alice' | 'Bob'\n",
    "V -> 'loves'\n",
    "\"\"\")\n",
    "text1 = nltk.tokenize.word_tokenize(\"Alice loves Bob\")\n",
    "print(text1)\n",
    "print()\n",
    "parser = nltk.ChartParser(text2)\n",
    "for tree in parser.parse(text1):\n",
    "    print(tree)\n",
    "tree.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse Tree 04 – Adjective Phrase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The little bear saw the fine fat trout in the brook\n",
    "\n",
    "Clue:\n",
    "NP --> DT Nom\n",
    "~~~~~~~~~~~~~\n",
    "Nom --> Adj N | Adj Adj N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unable to parse line 8: S-> V PP\nExpected an arrow",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/Anaconda/anaconda3/lib/python3.8/site-packages/nltk/grammar.py\u001b[0m in \u001b[0;36mread_grammar\u001b[0;34m(input, nonterm_parser, probabilistic, encoding)\u001b[0m\n\u001b[1;32m   1430\u001b[0m                 \u001b[0;31m# expand out the disjunctions on the RHS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1431\u001b[0;31m                 \u001b[0mproductions\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0m_read_production\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnonterm_parser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobabilistic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1432\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Anaconda/anaconda3/lib/python3.8/site-packages/nltk/grammar.py\u001b[0m in \u001b[0;36m_read_production\u001b[0;34m(line, nonterm_parser, probabilistic)\u001b[0m\n\u001b[1;32m   1334\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1335\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expected an arrow\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1336\u001b[0m     \u001b[0mpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected an arrow",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-57b3bfc33dd9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m text2 = nltk.CFG.fromstring(\"\"\"\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mS\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mNP\u001b[0m \u001b[0mDet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Anaconda/anaconda3/lib/python3.8/site-packages/nltk/grammar.py\u001b[0m in \u001b[0;36mfromstring\u001b[0;34m(cls, input, encoding)\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0ma\u001b[0m \u001b[0mgrammar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meither\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mform\u001b[0m \u001b[0mof\u001b[0m \u001b[0ma\u001b[0m \u001b[0mstring\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mstrings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m         \"\"\"\n\u001b[0;32m--> 546\u001b[0;31m         start, productions = read_grammar(\n\u001b[0m\u001b[1;32m    547\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstandard_nonterm_parser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         )\n",
      "\u001b[0;32m~/Anaconda/anaconda3/lib/python3.8/site-packages/nltk/grammar.py\u001b[0m in \u001b[0;36mread_grammar\u001b[0;34m(input, nonterm_parser, probabilistic, encoding)\u001b[0m\n\u001b[1;32m   1431\u001b[0m                 \u001b[0mproductions\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0m_read_production\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnonterm_parser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobabilistic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1432\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1433\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Unable to parse line {linenum + 1}: {line}\\n{e}\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1435\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mproductions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unable to parse line 8: S-> V PP\nExpected an arrow"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "text2 = nltk.CFG.fromstring(\"\"\"\n",
    "\n",
    "\n",
    "S -> NP Det \n",
    "NP -> ADJ NP \n",
    "NP -> ADJ N \n",
    "S -> CONJ->VP\n",
    "S-> V PP\n",
    "PP -> PREP NP\n",
    "NP-> DET NP\n",
    "NP-> ADJ N\n",
    "CONj VP\n",
    "VP-> V ADV\n",
    "\n",
    "PREP -> 'at'\n",
    "ADV->'away'\n",
    "Det -> 'The' | 'the'\n",
    "N -> 'dog' | 'cat'\n",
    "CONJ -> 'and'\n",
    "ADV -> 'away'\n",
    "V -> 'barked'|'chased' \n",
    "ADJ -> 'little' | 'yellow' | 'cute'\n",
    "\"\"\")\n",
    "\n",
    "text1 = nltk.tokenize.word_tokenize(\"The little yellow dog barked at the cute cat and chased away\")\n",
    "print(text1)\n",
    "print()\n",
    "parser = nltk.ChartParser(text2)\n",
    "for tree1 in parser.parse(text1):\n",
    "    tree1.draw()\n",
    "print(tree1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse Tree 05 – Adjective Phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP (Det the) (Nom (Adj angry) (Nom (N bear))))\n",
      "  (VP\n",
      "    (V chased)\n",
      "    (NP\n",
      "      (Det the)\n",
      "      (Nom (Adj frightened) (Nom (Adj little) (Nom (N squirrel)))))))\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "grammar2 = nltk.CFG.fromstring(\"\"\"\n",
    "S  -> NP VP\n",
    "NP -> Det Nom | Det N \n",
    "Nom -> Adj Nom | N\n",
    "VP -> V Adj | V NP | V | V NP PP\n",
    "PP -> P NP\n",
    "Det -> 'the'\n",
    "N -> 'bear' | 'squirrel'\n",
    "Adj  -> 'angry' | 'frightened' |  'little'\n",
    "V ->  'chased' \n",
    "\"\"\")\n",
    "\n",
    "sent = ['the', 'angry', 'bear', 'chased', 'the', 'frightened', 'little', 'squirrel']\n",
    "parser = nltk.ChartParser(grammar2)\n",
    "for tree in parser.parse(sent):\n",
    "    tree.draw()\n",
    "print(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse Tree 06 – Adverb Phrases (AdvP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ken', 'snores', 'very', 'loudly']\n",
      "(S (NP (N Ken)) (VP (V snores) (ADV (DEG very) (ADV loudly))))\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "sentence = \"Ken snores very loudly\"\n",
    "\n",
    "gram = nltk.CFG.fromstring(\"\"\"\n",
    "S -> NP VP\n",
    "NP -> N\n",
    "VP -> V ADV\n",
    "N -> 'Ken'\n",
    "V -> 'snores'\n",
    "DEG -> 'very'\n",
    "ADV -> DEG ADV | 'loudly'\n",
    "\"\"\")\n",
    "\n",
    "token = nltk.tokenize.word_tokenize(sentence)\n",
    "print(token)\n",
    "parser = nltk.ChartParser(gram)\n",
    "for tree in parser.parse(token):\n",
    "    tree.draw()\n",
    "print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unfortunately the cat killed the mouse\n",
      "(S\n",
      "  (ADV unfortunately)\n",
      "  (NP (DT the) (N cat))\n",
      "  (VP (V killed) (NP (DT the) (N mouse))))\n",
      "the cat unfortunately killed the mouse\n",
      "(S\n",
      "  (NP (DT the) (N cat))\n",
      "  (VP (ADV unfortunately) (VP (V killed) (NP (DT the) (N mouse)))))\n",
      "the cat killed the mouse unfortunately\n",
      "(S\n",
      "  (NP (DT the) (N cat))\n",
      "  (VP (VP (V killed) (NP (DT the) (N mouse))) (ADV unfortunately)))\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "sents = [\n",
    "    \"unfortunately the cat killed the mouse\",\n",
    "    \"the cat unfortunately killed the mouse\",\n",
    "    \"the cat killed the mouse unfortunately\"\n",
    "]\n",
    "\n",
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "S -> ADV NP VP | NP VP\n",
    "NP -> DT N\n",
    "VP -> ADV VP | VP ADV | V NP\n",
    "DT -> 'the'\n",
    "N -> 'cat' | 'mouse'\n",
    "V -> 'killed'\n",
    "ADV -> 'unfortunately'\n",
    "\"\"\")\n",
    "\n",
    "parser = nltk.ChartParser(grammar)\n",
    "\n",
    "for sent in sents:\n",
    "    print(sent)\n",
    "    for tree in parser.parse(word_tokenize(sent)):\n",
    "        tree.draw()\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
